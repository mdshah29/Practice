{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.__version__)\n",
    "pd?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of Pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series([0.2, 0.5, 0.75, 1.6])    #call the constructor and send the values as a list\n",
    "print(\"Pandas Series:\\n\" , series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes of Pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Series.values: \",series.values)   #to find the values in a series\n",
    "print(\"Index of Series: \", series.index)\n",
    "print(\"Data type of Series.values: \",series.values.dtype)\n",
    "print(\"Data type of   Series\", type(series.values))\n",
    "print(\"Type of Series\", type(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([5,4,3],  index=[100, 200, 300])  #creating a series with a given index, index has to be given as 2nd parameter\n",
    "print(\"Series is : \\n\", s, '\\n Indices are : ', s.index)\n",
    "print(\"Data type of   Series\", type(series.values)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Series from a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List=[20, 15, 42, 33, 94, 8, 5]    #Default indexing or Implicit Indexing\n",
    "print(\"List is: \" , List)\n",
    "print(\"Series from List\\n\", ser_list)\n",
    "print(\"Data type of   Series\", type(ser_list.values))\n",
    "print(\"Type of Series\", type(ser_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Explicit Indexing: \\n\",\n",
    "      pd.Series(List, index = ['i','ii','iii','iv','v','vi','vii']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the whole index of  a series\n",
    "s1= pd.Series([0,1,2,3,4])\n",
    "print(s1)\n",
    "s1.index=['A','B','C','E','E']\n",
    "print(s1['E'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Creating Series from numpy array\n",
    "###  Numpy 1D array vs Series\n",
    "Array contains implicit indexing, series has explicit indexing along with some additional capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([10, 20, 30, 40, 50])   #creating a numpy array\n",
    "ser_arr = pd.Series(arr)               #creating Series from a numpy array\n",
    "print(\"Pandas Series:\\n\" , ser_arr)\n",
    "print(\"Data type of   Series\", type(ser_arr.values))\n",
    "print(\"Type of Series\",type (ser_arr))    #Observe difference between dtype between List and array\n",
    "#dtype tells memory allocated to one item or element of an array. it is an array method\n",
    "#type() is like type(str)   dtype tells memory allocated like int32 float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_arr= np.random.random(5)\n",
    "index= ['a','b', 'c','d', 'e']   #index \n",
    "ser_arr=pd.Series(np_arr, index)\n",
    "print(\"Series \\n\", ser_arr)      #show that repition is allowed in index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating series from a dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'a':10, 'b':20, 'c':30, 'd':40, 'e':50}      #creating a Dictionary\n",
    "print(:dictinary os \", dict\")\n",
    "ser_dict = pd.Series(dict)         # creating a Series from a Dictionary\n",
    "print(\"Series is \\n\", ser_dict)\n",
    "print(\"b\" in ser_dict)\n",
    "print('Indices are : ', ser_dict.index,'\\n Elements of the series are : ', ser_dict.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={'monkey':153 ,'rat':212 ,'cotton':334 ,'fan':98}\n",
    "print(\"Dictionary is: \", d)\n",
    "ser_d=pd.Series(d)\n",
    "print(\"Series from Dictionary:\\n\", ser_d)\n",
    "print('Indices are : ', ser_d.index,'\\n Elements of the series are : ', ser_d.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acessing, Indexing and Slicing of Values in a series\n",
    "#Since a series is a Numpy array we can access elements using the default numeric index like array\n",
    "#array or list type of slicing\n",
    "ser_arr = pd.Series([10, 20, 30, 40, 50,60])\n",
    "print(ser_arr[3])\n",
    "print(ser_arr[1:4])      #array or list type of slicing\n",
    "print(ser_arr[:4])\n",
    "print(ser_arr[3:])\n",
    "print(ser_arr[1:6:2])\n",
    "print(ser_arr[: : 2])\n",
    "ser_arr[3]=100          #update of a series this means series values are mutable\n",
    "#print(ser_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# familiar attributes from NumPy arrays\n",
    "print(\"\\n ser_arr.size: \",ser_arr.size , \n",
    "      '\\n ser_arr.shape: ',ser_arr.shape,\n",
    "      '\\n ser_arr.ndim: ',ser_arr.ndim,\n",
    "      '\\n ser_arr.dtype: ',ser_arr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another way to slice a series is to select elements by specifying the index\n",
    "#Fancy Indexing\n",
    "ser_slice=pd.Series(ser_arr, index=[3,2])     #select rows with the index\n",
    "print(ser_slice)   \n",
    "print(ser_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing series elements in a dictionary way. this is with explicit index or key\n",
    "dict = {'a':10, 'b':20, 'c':30, 'd':40, 'e':50}      #creating a Dictionary\n",
    "print(\"dictinary is \", dict)\n",
    "ser_dict = pd.Series(dict)         # creating a Series from a Dictionary\n",
    "print(\"ser_dict['b']:\\n\", ser_dict['b'])   #Accessing oone element\n",
    "print(\"ser_dict['b':'e']:\\n \", ser_dict['b': 'e'])\n",
    "print(\"ser_dict[: 'd']:\\n\", ser_dict[:'d'])\n",
    "print(\"ser_dict[['b', 'e']]:\\n\",  ser_dict[['b', 'e']])    #Fancy Indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1= pd.Series([0,1,2,3,4], index=['A','B','C','D','E'])\n",
    "print(s1)\n",
    "#Series operations similar to sets and dictinary\n",
    "print('A' in s1)\n",
    "print(s1.keys())         #similarity to dictionary\n",
    "print(list(s1.items()))   #similarity to dictionary\n",
    "print(s1.values)      #access to dictionary values\n",
    "\n",
    "# extending the series like dictinaries\n",
    "s1['F'] = 5\n",
    "print(\"\\n After updation : \\n\",s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masking  on the values to extract subsets of data\n",
    "s1= pd.Series([10,20,30,40,50], index=['A','B','C','D','E'])\n",
    "print(s1)\n",
    "print('Masking')\n",
    "print(\"s1[(s1>10) & (s1<40)] \\n\", s1[(s1>10) & (s1<40)])\n",
    "#print('Fancy indexing')\n",
    "#print(\"s1[['A', 'C']] \\n\" , s1[['A', 'C']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing may be the source of the most confusion. Notice that when slicing with an explicit index (i.e. data['a':'c']), the final index is included in the slice, while when slicing with an implicit index (i.e. data[0:4]), the final index is excluded from the slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem that may arise with implicit and explicit indexing\n",
    "#Consider an Example where the explicit index is also a number\n",
    "s = pd.Series([5,4,3,2],  index=[100, 200, 300,400])  # index has to be given as 2nd parameter\n",
    "print(\"Series is : \\n\", s, '\\n Indices are : ', s.index) \n",
    "#print(s['100':'300'])\n",
    "print(s[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of this potential confusion in the case of integer indexes, Pandas provides some special indexer attributes\n",
    "loc() - explicit indexing  and iloc() always refers to  the implicit Python-style index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the loc() - indexing and slicing with explicit index\n",
    "#the iloc() - indexing and slicing with implicit index\n",
    "s = pd.Series([5,4,3,2],  index=[100, 200, 300,400])  # index has to be given as 2nd parameter\n",
    "print(\"Series is : \\n\", s, '\\n Indices are : ', s.index)\n",
    "print(\"Series with explicit index :s.loc[100:300]\\n\", s.loc[100:300])  #it will take the end value too\n",
    "print(\"Series with implicit index:  s.iloc[1:3] \\n\" , s.iloc[1:3])\n",
    "print('Implicit access  : s.iloc[2] \\n' , s.iloc[2])\n",
    "print('Explicit access  : s.loc[200] \\n' , s.loc[200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=pd.Series([6,7,8,9,5])\n",
    "s3 = pd.Series([1,2,3,4], index = ['a','b','c','d'])\n",
    "print('s1: \\n',s1,'s3: \\n',s3)\n",
    "s4 = s1.append(s3)    #Observe no copy is created \n",
    "print('Appended  series: \\n',s4 )\n",
    "# Delete a row with a particular element\n",
    "s4.drop(['c'])\n",
    "print(\"Series s4  after dropping 'c':\\n\",  s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aritmetic Functions \n",
    "### Elementwise Addition, Subtraction, Multiplication and Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Create two series \n",
    "s1=pd.Series([6,7,8,9,5])\n",
    "s2=pd.Series([0,1,2,3,4,5,7])\n",
    "print('Series are : \\n',s1, '\\n', s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series methods print('Addition of series: \\n', s1.add(s2))    #Elementwise addition\n",
    "print('\\n Subtraction of series: \\n', s1.sub(s2))    #Elementwise Subtraction\n",
    "print('\\n Multiplication of series: \\n', s1.mul(s2))\n",
    "print('\\n Division of series: \\n', s1.div(s2))\n",
    "print('Series are : \\n',s1, '\\n', s2)    #Series remains unchanged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Aggregate Functions  - Which reduce the series to a single number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMedian of series s2 is\", s2.median())\n",
    "print(\"\\n Mean of series s2 is \" , s2.mean())\n",
    "print(\"\\n Maximum of series s2 is\", s2.max())\n",
    "print(\"\\n Minimum of series s2 is\", s2.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Series with char/ string elements\n",
    "string=pd.Series(['a','b','c','S','e','J','g','B','P','o'])\n",
    "print('A Series wih String values: \\n ', string)\n",
    "print('string.str.upper(): \\n',string.str.upper())\n",
    "print('string.str.lower(): \\n',string.str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avoid this\n",
    "# Just as we can do slicing like an array on a series index we can also do set operations on an index but here \n",
    "#index should not have repitition\n",
    "# Index as ordered set\n",
    "indA = pd.Index([1, 3, 5, 7, 9])    #we can just create a Index object\n",
    "indB = pd.Index([2, 3, 5, 7, 11])\n",
    "\n",
    "print(indA & indB) # intersection\n",
    "print(indA | indB) # union\n",
    "print(indA ^ indB) # symmetric difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dont do this  #Index as an immutable array \n",
    "#Acessing, Indexing and Slicing of Indices in a series\n",
    "ser = pd.Series([10, 20, 30, 40, 50,60])\n",
    "#Index is like an ordered set\n",
    "print(ser.index)\n",
    "print(ser.index[3])\n",
    "print(ser.index[1:4])      #array or list type of slicing\n",
    "print(ser.index[:4])\n",
    "ser.index[3]=10    #index array cannot be updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Table with indexed rows and columns\n",
    "* can be seen as a sequence of aligned Series object, i.e., share same index\n",
    "* generalization of NumPy 2D Arrays\n",
    "* with heterogenous and/or missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'California': 3833, 'Texas': 8193, 'New York': 6511, 'Florida': 5560, 'Ohio': 1135} <class 'dict'>\n",
      "California    3833\n",
      "Texas         8193\n",
      "New York      6511\n",
      "Florida       5560\n",
      "Ohio          1135\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Dataframe as a stack of Series.  we create two columns using series and then make a DataFrame\n",
    "population_d= {'California': 3833, 'Texas': 8193,\n",
    "                'New York': 6511, 'Florida': 5560, 'Ohio': 1135}    #Statewise population \n",
    "print(population_d, type(population_d))\n",
    "population = pd.Series(population_d)\n",
    "print(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California    423967\n",
      "Texas         695662\n",
      "New York      141297\n",
      "Florida       170312\n",
      "Ohio          149995\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "area_d = {'California': 423967, 'Texas': 695662, 'New York': 141297,   \n",
    "             'Florida': 170312, 'Ohio': 149995}\n",
    "area = pd.Series(area_d) \n",
    "print(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame of States: \n",
      "             Population    Area\n",
      "California        3833  423967\n",
      "Texas             8193  695662\n",
      "New York          6511  141297\n",
      "Florida           5560  170312\n",
      "Ohio              1135  149995\n"
     ]
    }
   ],
   "source": [
    "states = pd.DataFrame({'Population': population,  'Area': area})  #two series with same index\n",
    "print(\"Data Frame of States: \\n\", states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n', states.index)     #row indices\n",
    "print('\\n', states.columns)    #column names\n",
    "print('\\n', states.values)\n",
    "print('\\n', states['Area'])     #access a column on a DataFrame like a key value pair\n",
    "print('\\n',states.Area)        #Columns can also be accessed as an Attribute\n",
    "#print('\\n',states.Area is states['Area'])\n",
    "print('\\n',states.loc['California'])   #accessing row of a dataframe with explicit index\n",
    "print('\\n', states.iloc[3])\n",
    "print('\\n', states.loc['California','Area'])\n",
    "print('\\n', states.iloc[3,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using Numpy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "num_arr=np.random.randn(6,4) #random delection of numbers following a standard normal distribution\n",
    "print(\"Array is : \\n\", num_arr)  \n",
    "cols=['A','B','C','D']    #arrays will not have index and columns\n",
    "df1=pd.DataFrame(num_arr, columns=cols, index = ['i', 'ii', 'iii', 'iv', 'v', 'vi'])\n",
    "#array of values, index, column\n",
    "print('\\n Data Frame from numpy array is : \\n')\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame as a Specialized Dictionary\n",
    " * DataFrame maps a column name to a Series of column data.\n",
    " * key is a column name and value is a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe using a dictionary of Lists, values are lists and column names are keys\n",
    "data= {'city' : ['Bombay', 'Chennai', 'Chennai', 'Delhi', 'Mysore' ], 'year' : [2001, 2005, 2003, 2001, 2000],  \n",
    "        'pop' : [25, 35, 20, 40, 15]}\n",
    "df2= pd.DataFrame(data)\n",
    "print(df2)\n",
    "#observe index is assigned automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe using a dictionary of Lists, values are lists and column names are keys\n",
    "data= {'city' : ['Bombay', 'Chennai', 'Chennai', 'Delhi', 'Mysore' ], 'year' : [2001, 2005, 2003, 2001, 2000],  \n",
    "        'pop' : [25, 35, 20, 40, 15]}   #this will have only columns no index\n",
    "labels=['a', 'b', 'c', 'd', 'e']\n",
    "df2= pd.DataFrame(data, index=labels)\n",
    "print(df2)\n",
    "#observe index is assigned automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise\n",
    "#create a dataframe from a list of dictionaries\n",
    "df3=pd.DataFrame([{'a': 1, 'b': 2, 'c':3, 'd':4}, {'a': 10, 'b': 20, 'c': 30}, {'a': 11, 'b': 21, 'c': 41, 'd': 51}])\n",
    "print(df3)  # creating a dataframe from a list of dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing DataFrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Animals  Age  Visits Priority\n",
      "a     cat  2.5       1        y\n",
      "b     cat  3.0       3        y\n",
      "c  turtle  0.5       2        n\n",
      "d     dog  NaN       3        y\n",
      "e     dog  5.0       2        n\n",
      "f     cat  2.0       3        n\n",
      "g  turtle  4.5       1        n\n",
      "h     cat  NaN       1        y\n",
      "i     dog  7.0       2        n\n",
      "j     dog  3.0       1        n\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#First Create a DataFrame\n",
    "data={'Animals': ['cat','cat','turtle','dog','dog','cat','turtle','cat','dog','dog'],\n",
    "          'Age': [2.5,3,0.5,np.nan,5,2,4.5,np.nan,7,3], \n",
    "      'Visits' : [1,3,2,3,2,3,1,1,2,1], \n",
    "    'Priority' : ['y','y','n','y','n','n','n','y','n','n']}\n",
    "labels=['a','b','c','d','e','f','g','h','i','j']\n",
    "animals_data=pd.DataFrame(data,index=labels)\n",
    "print(animals_data)\n",
    "print(type(animals_data))      #type of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Attributes  - index,  cols,  values, datatype of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n animals_data.index:\\n \", animals_data.index)\n",
    "print(\"\\n animals_data.columns:\\n\", animals_data.columns)\n",
    "print(\"\\n animals_data.values:\\n\", animals_data.values)      #will show only values without index and column names\n",
    "print(\"\\n animals_data.dtypes:\\n\", animals_data.dtypes)    #will show the datatype of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Visualizing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(animals_data)   #Visualizing complete may not be feasible in real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(animals_data.head())   # will display top 5 lines of the dataFrame\n",
    "print(animals_data.tail())     # will display bottom 5 lines of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details about the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about the whole dataframe\n",
    "print( animals_data.info()) #nrows, ncols, index, datatype of each column, number of nonnull values\n",
    "\n",
    "#statistical data of dataframe\n",
    "print('\\n Statistical Description : \\n',animals_data.describe())\n",
    "#mean std max min quartiles for columns with numeric type\n",
    "\n",
    "print('\\n Description for object values: \\n',animals_data.describe(include = ['object'])) \n",
    "#count, unique values, mode , freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Accessing/Slcing Data in a DataFrame\n",
    "* Indexing into a DataFrame is for retrieving one or more columns either with a single value or sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise\n",
    "print(\"\\n animals_data.index:\\n \", animals_data.index)    #accessing index\n",
    "print(\"\\n animals_data.columns:\\n\", animals_data.columns)    #accessing column names\n",
    "\n",
    "#Accessing columns of a DataFrame  2 ways\n",
    "print(\"\\n animals_data['Animals']:\\n\",animals_data['Animals'] )\n",
    "print(\"\\n animals_data['Age'] :\\n\", animals_data['Age'])\n",
    "\n",
    "print(\"\\n animals_data.Animal:\\n\",animals_data.Animals)\n",
    "animals_data[['Age','Visits']]   #Displaying particular Columns\n",
    "\n",
    "print(\"\\n animals_data.loc['b', 'Age']:\\n\",animals_data.loc['b', 'Age'])   #accessing by row and column\n",
    "animals_data.loc['b', 'Age'] =50\n",
    "\n",
    "print(\"\\n animals_data.loc['b', 'Age']:\\n\",animals_data.loc['b', 'Age'])   #updatinng a value in a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing rows of a DataFrame by implict and explicit index\n",
    "print(\"\\n animals_data.loc['a', :] :\\n\", animals_data.loc['a', :])   #values of a row are given as columns                                             \n",
    "print(\"\\ Rows 1 to 3 using slicing:\\n\",animals_data.iloc[1:3, 2:3] )      #iloc for implicit indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise\n",
    "#Acessing individual elements in the table by row and column\n",
    "print(animals_data)\n",
    "print(\"\\n animals_data.loc['b', 'Age']:\\n\",animals_data.loc['b', 'Age'])   #accessing by row and column\n",
    "animals_data.loc['b', 'Age'] =50\n",
    "print(\"\\n animals_data.loc['b', 'Age']:\\n\",animals_data.loc['b', 'Age'])   #updatinng a value in a Dataframe\n",
    "print(\"\\n animals_data.loc['b', 'Age']:\\n\",animals_data.iloc[2,2])   #accessing by row and column\n",
    "\n",
    "print(animals_data.iloc[:5, 2:4] )\n",
    "print(animals_data.loc['b':'e', 'Animals':'Visits'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Transpose of the Data Frame :\")\n",
    "animals_data.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting DataFrames\n",
    "* By default is ascending order\n",
    "* Mandatory to provide (by = ' '), Sort by one column\n",
    "* Can also combine sorting with slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methods in DataFrame object Sort By Values  \n",
    "print(animals_data)\n",
    "print(\"\\n Sorting the Data Agewise:\\n\", animals_data.sort_values(by = 'Age', ascending = False))   #sort by which column\n",
    "#Any missing value is sorted at end by default\n",
    "animals_data.sort_values(by='Age')[1:4]\n",
    "\n",
    "#Sort by index\n",
    "print(\"\\n Sorting the Data by Index:\\n\", animals_data.sort_index(axis=1)) #Since it is already sorted you dont see the change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReIndexing DataFrames\n",
    "* Reindexing allows you to change/add/delete the index on a specified axis. This returns a copy of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#. Create a new index  Reindexing\n",
    "print(animals_data)\n",
    "animals_data_reindex = animals_data.reindex(['d', 'e', 'g', 'f', 'a', 'b', 'c', 'i', 'j'])\n",
    "print(\"\\n ReIndexed Data: \\n\",animals_data.reindex)     #will not modify original data\n",
    "print(\"\\n Sorted by row index:\\n\", animals_data_reindex.sort_index(axis=0))\n",
    "print(\"\\n Sorted by Column Index:\\n\", animals_data_reindex.sort_index(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a copy of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_data_c=animals_data.copy()\n",
    "print(\"\\n Copy of animals_data:\\n\", animals_data_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting a row or Column of  a DataFrame\n",
    "* The drop() function modifies  the size or shape of a Series or DataFrame,\n",
    "* can manipulate an object in-place without returning a new object\n",
    "* Be careful with inplace as it destroys any data that is dropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(animals_data)\n",
    "print(\"Drop rows with names 'a; and 'b':\\n\", animals_data.drop(['a', 'b']))   #dropping rows\n",
    "#print(animals_data)\n",
    "#to drop the columns permanently use inplace - True\n",
    "print(\"Drop rows with names 'a; and 'b':\\n\", animals_data_c.drop(['a', 'b'], inplace=True))  \n",
    "print(\" Animals_data _c with inplace = true: \\n\", animals_data_c)\n",
    "\n",
    "print(animals_data.drop('Visits', axis=1)) \n",
    "#dropping column  columns are axis=1 for drop() default is row\n",
    "#So if we dont mention axis = 1 it will search for a row with name 'Visits'\n",
    "print(animals_data.drop('Visits', axis='columns'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Functions\n",
    "* All aggregation functions discussed in Series can be performed on columns of a DataFrame as each column is like a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why doing an Aggregation on a Row doesnt make sense\n",
    "print(\"Mean of the Dataframe is: \\n\",animals_data.mean())    #mean of values in columns containing numeric data\n",
    "print(\"\\nMean of 'Age' is: \",animals_data[['Age']].mean())\n",
    "print(\"\\nTotal visits :\",animals_data[['Visits']].sum())\n",
    "print(\"\\nMax visits: \",animals_data[['Visits']].max())\n",
    "print(\"\\nMin visits: \",animals_data[['Visits']].min())\n",
    "print(\"\\n Index of Max visits: \",animals_data[['Visits']].idxmax())\n",
    "print(\"\\n Index of Min visits: \",animals_data[['Visits']].idxmin())\n",
    "print(\"\\nSum: \\n\",animals_data.sum())     #for strings sum is string concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "* Difference between None and np.nan\n",
    "*For Series and DataFrame both None and np.nan are handled as np.nan\n",
    "* To detect missing values the isnull() and notnull() functions in Pandas are used\n",
    "*Filling of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trouble with missing data  \n",
    "#Why we need to drop missing values\n",
    "import numpy as np\n",
    "arr1 = np.array([1, None, 3, 4])    #observe None is a NoneType\n",
    "print(arr1,  arr1.dtype)\n",
    "print(arr1.sum())    #unsupported operand type(s) for +: 'int' and 'NoneType\n",
    "print(arr1.mean())\n",
    "arr2 = np.array([1, np.nan, 3,4])   #np.nan is a float type\n",
    "print(arr2,  arr2.dtype)  \n",
    "print(arr2.sum())                 #so np.nan is handled by  numpy  but not None\n",
    "print(arr2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series([1, np.nan, 2, None]))\n",
    "ser_null = pd.Series(range(5,8), dtype=int)\n",
    "print('\\n',ser_null)\n",
    "ser_null[0] = None \n",
    "print('\\n',ser_null)\n",
    "print('\\n',ser_null.sum())\n",
    "#casting the integer array to floating point, Pandas automatically converts the None to a NaN value.\n",
    "#Series datatype converts a None also to a nan and it can do the aggregation even with the nan values .\n",
    "#it ignores the nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1  2\n",
      "0  1.0  NaN  2\n",
      "1  2.0  3.0  5\n",
      "2  NaN  4.0  6\n",
      "0     3.0\n",
      "1     7.0\n",
      "2    13.0\n",
      "dtype: float64\n",
      "0     3.0\n",
      "1    10.0\n",
      "2    10.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Dataframe aggregation methods ignore nan values and find the sum\n",
    "data = pd.DataFrame([[1,      np.nan, 2],    \n",
    "                   [2,      3,      5],     \n",
    "                   [np.nan, 4,      6]])  \n",
    "print(data)\n",
    "print(data.sum())    #sum by default is column sum axis =0\n",
    "print(data.sum(axis=1))   #sum across columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Null Values\n",
    "* To detect missing values the isnull() and notnull() functions in Pandas are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.isnull(animals_data))    #isnull() function in pandas library\n",
    "#print(animals_data.isnull())      #isnull() in DataFrame object\n",
    "#Observe that Age has two missing values\n",
    "print(pd.notnull(animals_data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do this with a simpler example\n",
    "data = pd.DataFrame([[1,      np.nan, 2],    \n",
    "                   [2,      3,      5],     \n",
    "                   [np.nan, 4,      6]])  \n",
    "print('\\n data.isnull(): \\n',data.isnull())\n",
    "print('\\n data.notnull(): \\n',data.notnull())\n",
    "data[data.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Dropping Null values \n",
    "* dropna() drops all Null values - might drop good data\n",
    "* We specify how or thresh parameters\n",
    "* DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "* how(any,all)\n",
    "* ‘any’ : If any NA values are present, drop that row or column.\n",
    "* ‘all’ : If all values are NA, drop that row or column. thresh - 3 means requires that many nonNA values\n",
    "* inplace is True or False\n",
    "* For finer-grained control, the thresh parameter specifies a min no. of non-null values for the row/column to be kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping null values\n",
    "print(data.dropna())\n",
    "data.dropna(axis='rows', thresh=2)   #axis =0 means drop rows which have missing values, 1 cols which have missing values\n",
    "data.dropna(axis='columns', thresh = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling Missing values\n",
    "* We may choose to fill in different data according to the data type of the column\n",
    "* Both numpy.nan and None can be filled in using pandas.fillna(). \n",
    "* For categorical columns (string columns), we want to fill in the missing values with mode. \n",
    "* For numerical columns, we want to fill in the missing values with mean\n",
    "* DataFrame.fillna(value=None, method=None, axis=None, inplace=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([[1,      np.nan, 2],    \n",
    "                   [2,      3,      5],     \n",
    "                   [np.nan, 4,      6]]) \n",
    "print(data)\n",
    "#print(data.fillna(0))     we can fill with column mean or mode for categorical data\n",
    "#print(data.fillna(method='ffill'))\n",
    "print(data.fillna(method='bfill'))\n",
    "print(data)          # original data will not change, to change we need to set inplace = True\n",
    "#find mean of each column and fill each individually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reading a csv and excel file into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First write dataframe to csv then read it back\n",
    "data={'Animals': ['cat','cat','turtle','dog','dog','cat','turtle','cat','dog','dog'],\n",
    "          'Age': [2.5,3,0.5,np.nan,5,2,4.5,np.nan,7,3], \n",
    "      'Visits' : [1,3,2,3,2,3,1,1,2,1], \n",
    "    'Priority' : ['y','y','n','y','n','n','n','y','n','n']}\n",
    "labels=['a','b','c','d','e','f','g','h','i','j']\n",
    "animals_data=pd.DataFrame(data,index=labels)\n",
    "data.to_csv('animal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_animal=pd.read_csv('animal.csv')\n",
    "df_animal.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('animal.xlsx',sheet_name='sheet1')\n",
    "df_animal2=pd.read_excel('animal.xlsx', 'sheet1',\n",
    "                         index_col=None, na_values=['NA'])\n",
    "df_animal2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining DataSets\n",
    "* Pandas concatenation preserves indices, even if it results in duplicate indices.\n",
    "* Series Concatenation\n",
    "* DataFrame Concatenation :  Concatenation one below another (axis=0) , Concatenation side by side (axis=1)\n",
    "* Ignore Index while concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series 1 : \n",
      " 1    A\n",
      "2    B\n",
      "3    C\n",
      "dtype: object \n",
      "Series 2 : \n",
      " 4    D\n",
      "5    E\n",
      "6    F\n",
      "dtype: object\n",
      "Concatenating series: \n",
      " 1    A\n",
      "2    B\n",
      "3    C\n",
      "4    D\n",
      "5    E\n",
      "6    F\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "ser1 = pd.Series(['A', 'B', 'C'], index=[1, 2, 3]) \n",
    "ser2 = pd.Series( ['D', 'E', 'F'], index=[4, 5, 6] )     #test with the same index\n",
    "print(\"Series 1 : \\n\",ser1, \"\\nSeries 2 : \\n\",ser2)\n",
    "print(\"Concatenating series: \\n\", pd.concat([ser1, ser2]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* DataFrame Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame 1 : \n",
      "      A    B    C\n",
      "1  axe  bat  cap\n",
      "2  art  bar  cat\n",
      "3  ant  bin  car \n",
      " Data Frame 2: \n",
      "      D    E    F\n",
      "2  dam  ear  fan\n",
      "3  den  eat  fog\n",
      "6  dot  egg  fat\n",
      "Concatenating Data Frames: \n",
      "      A    B    C    D    E    F\n",
      "1  axe  bat  cap  NaN  NaN  NaN\n",
      "2  art  bar  cat  NaN  NaN  NaN\n",
      "3  ant  bin  car  NaN  NaN  NaN\n",
      "2  NaN  NaN  NaN  dam  ear  fan\n",
      "3  NaN  NaN  NaN  den  eat  fog\n",
      "6  NaN  NaN  NaN  dot  egg  fat\n",
      "Concatenating Data Frames along axis 1: \n",
      "      A    B    C    D    E    F\n",
      "1  axe  bat  cap  NaN  NaN  NaN\n",
      "2  art  bar  cat  dam  ear  fan\n",
      "3  ant  bin  car  den  eat  fog\n",
      "6  NaN  NaN  NaN  dot  egg  fat\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'A' : ['axe', 'art', 'ant'], 'B' : ['bat', 'bar', 'bin'], 'C' : ['cap', 'cat', 'car']},\n",
    "                   index = [1,2,3])\n",
    "df2 = pd.DataFrame({'D' : ['dam', 'den', 'dot'], 'E': [ 'ear', 'eat', 'egg'], 'F': ['fan', 'fog', 'fat']}, \n",
    "                   index =[ 2, 3, 6])\n",
    "print(\"Data frame 1 : \\n\", df1,'\\n Data Frame 2: \\n', df2)\n",
    "print(\"Concatenating Data Frames: \\n\",pd.concat([df1,df2], axis=0))  # axis =0 is stacking one below the other\n",
    "print(\"Concatenating Data Frames along axis 1: \\n\",pd.concat([df1,df2], axis = 1))\n",
    "#will consider common indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ignoring the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df1, df2], ignore_index = True)\n",
    "print(\"Concatenation of dataframes while ignoring the index: \\n\", df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Joining DataFrames\n",
    "* Inner Join  - Concatenation of common columns ie intersection of two dataframes\n",
    "* concat is like outer join\n",
    "* Using append() Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Inner Join on dataframes : \n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [1, 2, 3, 2, 3, 6]\n"
     ]
    }
   ],
   "source": [
    "print(\" Inner Join on dataframes : \\n\", pd.concat([df1, df2], join = 'inner')) #no overlapping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exercise\n",
    "df3 = pd.DataFrame({'B' : ['ball', 'box' , 'band'], 'C': ['cat', 'calendar', 'cone'],'G' : ['grain', 'grape', 'goat']} ,\n",
    "                   index =[ 1, 4, 2])\n",
    "print(\"Data Frame 1 : \\n\", df1, \"Data Frame 3 : \\n\", df3)\n",
    "print(\" Joining Data frmes:  \\n\" , pd.concat([df1, df3]))   #stacking one below another\n",
    "print(\" Joining Data frmes along axis = 1:  \\n\" , pd.concat([df1, df3], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Inner Join on dataframes : \n",
      "       B         C\n",
      "1   bat       cap\n",
      "2   bar       cat\n",
      "3   bin       car\n",
      "1  ball       cat\n",
      "4   box  calendar\n",
      "2  band      cone\n"
     ]
    }
   ],
   "source": [
    "print(\" Inner Join on dataframes : \\n\", pd.concat([df1, df3], join = 'inner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### The append() \n",
    "* the append() method in Pandas does not modify the original object—instead, it creates a new object with the combined data\n",
    "* not very efficient method as a new index and data buffer is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1)\n",
    "print(df2)\n",
    "print(df1.append(df2))    # append is same as concat stocks dataframes one below another\n",
    "print(df1)       # Original DataFrames are not update\n",
    "print(df2)         # a new ccatenated dataframe is created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Operations\n",
    "* Pandas has join operations identical to SQL\n",
    "* pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=True)\n",
    "* left, right- dataframes, One of 'left', 'right', 'outer', 'inner\n",
    "* on - Column to join, default is common column, left_on- column in left dataframe to use as keys\n",
    "* left_index- True means use left dataframe index as join key, sort - True Sort result by joining Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student dataframe: \n",
      "    St_id Branch\n",
      "0    101     IT\n",
      "1    102     CS\n",
      "2    103    ECE\n",
      "3    104     CS\n",
      "4    105   Mech \n",
      "Faculty Dataframe :\n",
      "    F_id F_name Branch\n",
      "0   110      A    ECE\n",
      "1   120      B   Mech\n",
      "2   130      C    EEE\n",
      "3   140      D     IT\n",
      "4   150      E     CS\n",
      "Merged dataframe : \n",
      "     St_id Branch  F_id F_name\n",
      "0    101     IT   140      D\n",
      "1    102     CS   150      E\n",
      "2    104     CS   150      E\n",
      "3    103    ECE   110      A\n",
      "4    105   Mech   120      B\n"
     ]
    }
   ],
   "source": [
    "df_stud = pd.DataFrame({'St_id': [101,102,103,104,105],'Branch': ['IT','CS','ECE','CS','Mech']})\n",
    "df_fac = pd.DataFrame({'F_id' : [110,120,130,140,150 ],'F_name' : ['A', 'B', 'C', 'D', 'E'],'Branch': ['ECE','Mech', 'EEE', \"IT\", 'CS'] })\n",
    "print(\"Student dataframe: \\n\", df_stud,'\\nFaculty Dataframe :\\n', df_fac)\n",
    "df_merge = pd.merge(df_stud, df_fac)\n",
    "print(\"Merged dataframe : \\n \", df_merge)   #Merge on a common column\n",
    "#works only if both dataframes have the specified column Default is inner\n",
    "#print(\"Merged dataframe : \\n \", pd.merge(df_stud, df_fac, on = 'Branch') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When similar columns have different names in different dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Details : \n",
      "    St_id Branch\n",
      "0    101     IT\n",
      "1    102     CS\n",
      "2    103    ECE\n",
      "3    104     CS\n",
      "4    105   Mech Faculty Details: \n",
      "    F_id F_name Branch\n",
      "0   110      A    ECE\n",
      "1   120      B   Mech\n",
      "2   130      C    EEE\n",
      "3   140      D     IT\n",
      "4   150      E     CS\n",
      "Merged Dataframes : \n",
      "    St_id Branch F_name Stream\n",
      "0    101     IT      D     IT\n",
      "1    102     CS      E     CS\n",
      "2    104     CS      E     CS\n",
      "3    103    ECE      A    ECE\n",
      "4    105   Mech      B   Mech\n",
      "Student Details : \n",
      "    St_id Branch\n",
      "0    101     IT\n",
      "1    102     CS\n",
      "2    103    ECE\n",
      "3    104     CS\n",
      "4    105   Mech Faculty Details: \n",
      "    F_id F_name Branch\n",
      "0   110      A    ECE\n",
      "1   120      B   Mech\n",
      "2   130      C    EEE\n",
      "3   140      D     IT\n",
      "4   150      E     CS\n"
     ]
    }
   ],
   "source": [
    "df_fac1 = pd.DataFrame({'F_name' : ['A', 'B', 'C', 'D', 'E'],'Stream': ['ECE','Mech', 'EEE', \"IT\", 'CS'] })\n",
    "print(\"Student Details : \\n\", df_stud, 'Faculty Details: \\n', df_fac)\n",
    "print(\"Merged Dataframes : \\n\", pd.merge(df_stud, df_fac1, left_on = 'Branch', right_on = 'Stream'))\n",
    "print(\"Student Details : \\n\", df_stud, 'Faculty Details: \\n', df_fac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the redundant column can also be dropped\n",
    "pd.merge(df_stud, df_fac, left_on = 'Branch', right_on = 'Stream').drop('Stream', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge over indices\n",
    " * left_index and right_index flags can be used to perform merge over the similar index of the dataframes.\n",
    " * Also, join( ) method performs the merge by default on indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Details : \n",
      "         St_id\n",
      "Branch       \n",
      "IT        101\n",
      "CS        102\n",
      "ECE       103\n",
      "CS        104\n",
      "Mech      105 Faculty Details: \n",
      "        F_name\n",
      "Stream       \n",
      "ECE         A\n",
      "Mech        B\n",
      "EEE         C\n",
      "IT          D\n",
      "CS          E\n",
      "\n",
      "Using merge on indices: \n",
      "       St_id F_name\n",
      "CS      102      E\n",
      "CS      104      E\n",
      "ECE     103      A\n",
      "IT      101      D\n",
      "Mech    105      B\n",
      "\n",
      "Using join( ): \n",
      "       St_id F_name\n",
      "CS      102      E\n",
      "CS      104      E\n",
      "ECE     103      A\n",
      "IT      101      D\n",
      "Mech    105      B\n"
     ]
    }
   ],
   "source": [
    "#print('\\n Using merge on indices: \\n',pd.merge(df_stud, df_fac, left_index=True, right_index=True))\n",
    "#print('\\n Using join( ): \\n', df_stud.join(df_fac))\n",
    "#If we use default index branch is repeated. better way is to set the common column as index\n",
    "\n",
    "df1 = df_stud.set_index('Branch')\n",
    "df2 = df_fac1.set_index('Stream')\n",
    "print(\"Student Details : \\n\", df1, 'Faculty Details: \\n', df2)\n",
    "print('\\nUsing merge on indices: \\n',pd.merge(df1, df2, left_index=True, right_index=True))\n",
    "print('\\nUsing join( ): \\n', df1.join(df2))\n",
    "#DataFrame has a convenient join method for merging by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Different types of joins can also be specified like 'inner' , 'outer', 'left' and 'right' using how keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see the effect of outer Join which is like Union we need to add different elements to Branch\n",
    "df_stud = pd.DataFrame({'St_id': [101,102,103,104,105,106],'Branch': ['IT','CS','ECE','CS','Mech', ' EEE']})\n",
    "df_fac = pd.DataFrame({'F_id' : [120,130,140,150 ],'F_name' : ['B', 'C', 'D', 'E'],'Branch': ['Mech', 'EEE', \"IT\", 'CS'] })\n",
    "print(\"Student dataframe: \\n\", df_stud,'\\nFaculty Dataframe :\\n', df_fac)\n",
    "\n",
    "df_merge = pd.merge(df_stud, df_fac, on = 'Branch', how='right')\n",
    "print(\"Merged dataframe : \\n \", df_merge)   #Merge on a common column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-to-one join\n",
    "* uses a common column as the key to join the dataframe.\n",
    "* the order of values in each column in not necessarily maintained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd. DataFrame({'key' :['b', 'a', 'd','e'], 'data1': range(4)}) #has unique  rows labels\n",
    "df2 =pd. DataFrame({'key' :['a', 'b', 'd'], 'data2': range(3)})   # has unique row labels\n",
    "print(\"DataFrame1 : \\n\", df1, '\\nDataFrame2 :\\n', df2)\n",
    "\n",
    "#Example of one  to one merge situation\n",
    "#print(\"Inner Join:\\n\", pd.merge(df1, df2, on ='key', how = 'inner', sort=True))     # intersection of keys \n",
    "#print(\"Outer Join:\\n\", pd.merge(df1, df2, on ='key', how = 'outer', sort=True))     # union of keys\n",
    "#print(\"Left Join:\\n\", pd.merge(df1, df2, on ='key', how = 'left', sort=True))     #  keys from left dataframe\n",
    "#print(\"Right Join:\\n\", pd.merge(df1, df2, on ='key', how = 'right', sort=True))     # \n",
    "#Here left and outer is same and Right and Inner is same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Many-to-one joins\n",
    "- one of the two key columns contains duplicate entries.\n",
    "- the merged DataFrame preserves the duplicate entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =pd. DataFrame({'key' :['b', 'b', 'a', 'c', 'a', 'a'], 'data1': range(6)}) #has multiple rows labelled a and b\n",
    "df2 = pd. DataFrame({'key' :['a', 'b', 'd'], 'data2': range(3)})\n",
    "print(\"DataFrame1 : \\n\", df1, '\\nDataFrame2 :\\n', df2)\n",
    "\n",
    "#Example of many to one merge situation\n",
    "#No of rows will be 5X2 \n",
    "#print(\"Inner Join:\\n\", pd.merge(df1, df2, on ='key', how = 'inner', sort=True))     # intersection of keys \n",
    "#print(\"Outer Join:\\n\", pd.merge(df1, df2, on ='key', how = 'outer', sort=True))     # union of keys\n",
    "#print(\"Left Join:\\n\", pd.merge(df1, df2, on ='key', how = 'left', sort=True))     #  keys from left dataframe\n",
    "#print(\"Right Join:\\n\", pd.merge(df1, df2, on ='key', how = 'right', sort=True))     # \n",
    "#Here left and outer is same and Right and Inner is same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Many-to-many join\n",
    "* when the key column in both the left and right array contins duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =pd. DataFrame({'key' : ['b', 'b', 'a','c', 'a', 'a', 'b'], 'data1': range(7)})  #has multiple rows labelled a and b\n",
    "df2 = pd.DataFrame({'key' : ['a', 'b', 'a', 'b', 'd'], 'data2': range(5)})\n",
    "print(\"DataFrame1 : \\n\", df1, '\\nDataFrame2 :\\n', df2)\n",
    "\n",
    "#Example of many to one merge situation\n",
    "#No of rows in the dataframe = 7x4 for inner\n",
    "#No of rows will be 5X2 \n",
    "print(\"Inner Join:\\n\", pd.merge(df1, df2, on ='key', how = 'inner', sort=True))     # intersection of keys \n",
    "#print(\"Outer Join:\\n\", pd.merge(df1, df2, on ='key', how = 'outer', sort=True))     # union of keys\n",
    "#print(\"Left Join:\\n\", pd.merge(df1, df2, on ='key', how = 'left', sort=True))     #  keys from left dataframe\n",
    "#print(\"Right Join:\\n\", pd.merge(df1, df2, on ='key', how = 'right', sort=True))     # \n",
    "#Here left and outer is same and Right and Inner is same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series([2,3,4,5])\n",
    "print(series[2])\n",
    "series[2]=7.8\n",
    "print(series[2])\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas.merge connects rows in DataFrames based on one or more keys. This\n",
    "* will be familiar to users of SQL or other relational databases, as it implements database join operations\n",
    "* left LEFT OUTER JOIN\tUse keys from left object\n",
    "* right\tRIGHT OUTER JOIN\tUse keys from right object\n",
    "* outer\tFULL OUTER JOIN\tUse union of keys\n",
    "* inner\tINNER JOIN\tUse intersection of keys\n",
    "\n",
    "• pandas.concat concatenates or “stacks” together objects along an axis.### The merge method() is equivalent to the SQL join"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dir( String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2\n",
      "0  1  4  2\n",
      "1  2  3  5\n",
      "2  7  4  6\n",
      "0    10\n",
      "1    11\n",
      "2    13\n",
      "dtype: int64\n",
      "0     7\n",
      "1    10\n",
      "2    17\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Difference beytween axis =0 and axis =1\n",
    "#Dataframe aggregation methods ignore nan values and find the sum\n",
    "data = pd.DataFrame([[1,  4,  2],    \n",
    "                   [2,   3, 5],     \n",
    "                   [7,  4,  6]])  \n",
    "print(data)\n",
    "print(data.sum())    #sum by default is column sum axis =0  columnwise sum\n",
    "print(data.sum(axis=1))   #roqwwise sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
